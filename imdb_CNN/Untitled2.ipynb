{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1672212801470,"user":{"displayName":"salad xx","userId":"13786222985564916523"},"user_tz":-480},"id":"ts_EnZT7n7To"},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":615,"status":"ok","timestamp":1672212602100,"user":{"displayName":"salad xx","userId":"13786222985564916523"},"user_tz":-480},"id":"4k9MRKRJoDnp","outputId":"c2547056-0ae6-498a-c26d-587393b9c8db"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"]}],"source":["dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,as_supervised=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":474,"status":"ok","timestamp":1672212620414,"user":{"displayName":"salad xx","userId":"13786222985564916523"},"user_tz":-480},"id":"EvhhCMBfopqq","outputId":"fcfecef6-5bed-4f32-f36c-905711f4ae58"},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulary size:  8185\n"]}],"source":["#获取训练集、测试集\n","train_dataset, test_dataset = dataset['train'], dataset['test'] \n","\n","#获取tokenizer对象，用进行字符处理级id转换(这里先转换成subword，再转换为id)等操作 \n","tokenizer = info.features['text'].encoder\n","print('vocabulary size: ', tokenizer.vocab_size)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":604,"status":"ok","timestamp":1672212626823,"user":{"displayName":"salad xx","userId":"13786222985564916523"},"user_tz":-480},"id":"eW6MPldfovbK","outputId":"b3eeec6e-667e-4581-dfd6-fdbe5e9c6259"},"outputs":[{"name":"stdout","output_type":"stream","text":["tokened id:  [4025, 222, 2621, 1199, 6307, 2327, 2934]\n"]}],"source":["#token对象测试\n","sample_string = 'Hello word , Tensorflow'\n","tokenized_string = tokenizer.encode(sample_string)\n","print('tokened id: ', tokenized_string)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":512,"status":"ok","timestamp":1672212675921,"user":{"displayName":"salad xx","userId":"13786222985564916523"},"user_tz":-480},"id":"vXtbAi3HoFO4","outputId":"b43e1af1-5e43-4111-adfd-80b6e4c999a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["original string:  Hello word , Tensorflow\n"]}],"source":["#解码还原字符串\n","src_string = tokenizer.decode(tokenized_string) \n","print('original string: ', src_string) "]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":508,"status":"ok","timestamp":1672212715857,"user":{"displayName":"salad xx","userId":"13786222985564916523"},"user_tz":-480},"id":"ZfWsnDCYpIOY","outputId":"8c8afad3-b867-4978-a3ca-988ad2296c25"},"outputs":[{"name":"stdout","output_type":"stream","text":["4025-\u003e[Hell]\n","222-\u003e[o ]\n","2621-\u003e[word]\n","1199-\u003e[ , ]\n","6307-\u003e[Ten]\n","2327-\u003e[sor]\n","2934-\u003e[flow]\n"]}],"source":["#解出每个subword\n","for t in tokenized_string:\n"," print(str(t)+'-\u003e['+tokenizer.decode([t])+ ']') "]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1672212747205,"user":{"displayName":"salad xx","userId":"13786222985564916523"},"user_tz":-480},"id":"PLIuIJaApSUx"},"outputs":[],"source":["#构建批次训练集\n","BUFFER_SIZE=10000\n","BATCH_SIZE = 64\n","\n","train_dataset = ( train_dataset\n","    .shuffle(BUFFER_SIZE)\n","    .padded_batch(BATCH_SIZE))\n","test_dataset = (\n","    test_dataset\n","    .padded_batch(BATCH_SIZE))"]},{"cell_type":"markdown","metadata":{"id":"FGPpzg23oQx6"},"source":["## 模型构建"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1211,"status":"ok","timestamp":1672212842434,"user":{"displayName":"salad xx","userId":"13786222985564916523"},"user_tz":-480},"id":"AOiJ5Wh6oSPR"},"outputs":[],"source":["def get_model():\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","  return model\n","\n","model = get_model()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":510,"status":"ok","timestamp":1672212854205,"user":{"displayName":"salad xx","userId":"13786222985564916523"},"user_tz":-480},"id":"ZFJWOjuDpv5a"},"outputs":[],"source":["model.compile(loss='binary_crossentropy',\n","       optimizer='adam',\n","       metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"oPXStvMfpy6v"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","391/391 [==============================] - 1036s 3s/step - loss: 0.5521 - accuracy: 0.7118 - val_loss: 0.4734 - val_accuracy: 0.8001\n","Epoch 2/10\n","391/391 [==============================] - 1002s 3s/step - loss: 0.3818 - accuracy: 0.8442 - val_loss: 0.4380 - val_accuracy: 0.8042\n","Epoch 3/10\n","391/391 [==============================] - 1015s 3s/step - loss: 0.3105 - accuracy: 0.8768 - val_loss: 0.3959 - val_accuracy: 0.8385\n","Epoch 4/10\n","391/391 [==============================] - 1023s 3s/step - loss: 0.2418 - accuracy: 0.9077 - val_loss: 0.4113 - val_accuracy: 0.8331\n","Epoch 5/10\n","391/391 [==============================] - 1015s 3s/step - loss: 0.2444 - accuracy: 0.9027 - val_loss: 0.4425 - val_accuracy: 0.8318\n","Epoch 6/10\n","391/391 [==============================] - 1006s 3s/step - loss: 0.1782 - accuracy: 0.9352 - val_loss: 0.5234 - val_accuracy: 0.8017\n","Epoch 7/10\n","391/391 [==============================] - 1016s 3s/step - loss: 0.1564 - accuracy: 0.9412 - val_loss: 0.5627 - val_accuracy: 0.8052\n","Epoch 8/10\n","391/391 [==============================] - 990s 3s/step - loss: 0.2894 - accuracy: 0.8758 - val_loss: 0.8050 - val_accuracy: 0.7794\n","Epoch 9/10\n","391/391 [==============================] - 997s 3s/step - loss: 0.1606 - accuracy: 0.9393 - val_loss: 0.6030 - val_accuracy: 0.7827\n","Epoch 10/10\n","391/391 [==============================] - 988s 3s/step - loss: 0.1980 - accuracy: 0.9206 - val_loss: 0.7130 - val_accuracy: 0.8161\n"]}],"source":["history = model.fit(train_dataset, epochs=5,validation_data=test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"_sJ6v8NEp8Wg"},"source":["## 可视化"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZlowhW-cp5eE"},"outputs":[],"source":["# 查看训练过程\n","import matplotlib.pyplot as plt\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel('epochs')\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.show()\n","plot_graphs(history, 'accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzU__eIsqGUH"},"outputs":[],"source":["plot_graphs(history, 'loss')"]},{"cell_type":"markdown","metadata":{"id":"crxDCW3dqd7o"},"source":["## 模型测试"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yjIlu-OOqcg1"},"outputs":[],"source":["test_loss, test_acc = model.evaluate(test_dataset)\n","print('test loss: ', test_loss)\n","print('test acc: ', test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jaJL6xSxqkqa"},"outputs":[],"source":["def pad_to_size(vec, size):\n","  zeros = [0] * (size-len(vec))\n","  vec.extend(zeros)\n","  return vec\n","\n","def sample_predict(sentence, pad=False):\n","  tokened_sent = tokenizer.encode(sentence)\n","  if pad:\n","    tokened_sent = pad_to_size(tokened_sent, 64)\n","  pred = model.predict(tf.expand_dims(tokened_sent, 0))\n","  return pred\n","\n","# 没有padding的情况\n","sample_pred_text = ('The movie was cool. The animation and the graphics '\n","          'were out of this world. I would recommend this movie.')\n","predictions = sample_predict(sample_pred_text, pad=False)\n","print(predictions)\n","\n","# 有padding的情况\n","sample_pred_text = ('The movie was cool. The animation and the graphics '\n","          'were out of this world. I would recommend this movie.')\n","predictions = sample_predict(sample_pred_text, pad=True)\n","print (predictions)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO15gUKTWXemGaXYGwkEcso","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}